test_suite:
  - name: "Conv Activation Pool FC Layer"
    layers:
      # Layer 1: Simple convolution on 28x28 input -> 14x14 output
      - type: convolution
        config:
          kernel_size: 2
          stride: 2
          padding: 0
          input_shape: [28, 28]
          input_channels: 1
          output_channels: 1
          data_range: [0, 50]
          weight_range: [-1, 1]
          quantize_weights: true
          quantize_output: true

      # Layer 2: ReLU activation on 14x14 input -> 14x14 output
      - type: activation
        config:
          activation_type: relu
          input_shape: [14, 14]
          data_range: [-128, 127]
      
      # Layer 2: Avg pooling on 14x14 input -> 7x7 output
      - type: pooling
        config:
          kernel_size: 2
          stride: 2
          pool_type: avg
          input_shape: [14, 14]
          data_range: [0, 127]
      
      # Layer 3: Fully connected layer on 7x7 input -> 10 output neurons
      - type: fully_connected
        config:
          input_size: 49
          output_size: 10
          use_bias: true
          data_range: [-128, 127]
          weight_range: [-128, 127]